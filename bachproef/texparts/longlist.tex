\chapter{longlist}



\section{web-llm}

Veel huidige implementaties waarbij de rekenkracht van \textit{WebGPU} wordt ingezet voor \textit{large language models} ondersteuning in de browser maken gebruik van \href{https://github.com/mlc-ai/web-llm}{web-llm}, dit is een \textit{open source} project onder de \textit{Apache License, Version 2.0}.

\bigbreak{}

Web-llm laat toe dat \textit{large language models} direct beschikbaar zijn in de browser door middel van WebGPU. Het is een Javascript implementatie, en de software is beschikbaar als een \textit{npm} package.

\begin{displayquote}
    "WebLLM is fully compatible with OpenAI API. That is, you can use the same OpenAI API on any open source models locally, with functionalities including json-mode, function-calling, streaming, etc."\\ \autocite{mlcai2023}
\end{displayquote}

\section{embd}

embd van Fleetwood. \autocite{Fleetwood2023c}

\section{Whisper turbo}

Whisper turbo van Fleetwood. \autocite{Fleetwood2023b}

\section{Wgpu-bench}

Wgpu-bench van Fleetwood. \autocite{Fleetwood2023d}

\section{Markdown editor}

Markdown editor van Nico Martin. \autocite{Martin2020}

\section{webgpu-embedding-benchmark}

webgpu-embedding-benchmark van Joshua Lochner. \autocite{Lochner2024}