\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}%
\label{ch:stand-van-zaken}

% Tip: Begin elk hoofdstuk met een paragraaf inleiding die beschrijft hoe
% dit hoofdstuk past binnen het geheel van de bachelorproef. Geef in het
% bijzonder aan wat de link is met het vorige en volgende hoofdstuk.

% Pas na deze inleidende paragraaf komt de eerste sectiehoofding.

% Dit hoofdstuk bevat je literatuurstudie. De inhoud gaat verder op de inleiding, maar zal het onderwerp van de bachelorproef *diepgaand* uitspitten. De bedoeling is dat de lezer na lezing van dit hoofdstuk helemaal op de hoogte is van de huidige stand van zaken (state-of-the-art) in het onderzoeksdomein. Iemand die niet vertrouwd is met het onderwerp, weet nu voldoende om de rest van het verhaal te kunnen volgen, zonder dat die er nog andere informatie moet over opzoeken \autocite{Pollefliet2011}.

% Je verwijst bij elke bewering die je doet, vakterm die je introduceert, enz.\ naar je bronnen. In \LaTeX{} kan dat met het commando \texttt{$\backslash${textcite\{\}}} of \texttt{$\backslash${autocite\{\}}}. Als argument van het commando geef je de ``sleutel'' van een ``record'' in een bibliografische databank in het Bib\LaTeX{}-formaat (een tekstbestand). Als je expliciet naar de auteur verwijst in de zin (narratieve referentie), gebruik je \texttt{$\backslash${}textcite\{\}}. Soms is de auteursnaam niet expliciet een onderdeel van de zin, dan gebruik je \texttt{$\backslash${}autocite\{\}} (referentie tussen haakjes). Dit gebruik je bv.~bij een citaat, of om in het bijschrift van een overgenomen afbeelding, broncode, tabel, enz. te verwijzen naar de bron. In de volgende paragraaf een voorbeeld van elk.

% \textcite{Knuth1998} schreef een van de standaardwerken over sorteer- en zoekalgoritmen. Experten zijn het erover eens dat cloud computing een interessante opportuniteit vormen, zowel voor gebruikers als voor dienstverleners op vlak van informatietechnologie~\autocite{Creeger2009}.

% Let er ook op: het \texttt{cite}-commando voor de punt, dus binnen de zin. Je verwijst meteen naar een bron in de eerste zin die erop gebaseerd is, dus niet pas op het einde van een paragraaf.

\section{Rekenkracht op het web}
\label{sec:PowerOnWeb}

Rekenkundige taken op het web werden voorheen in beperkte mate uitgevoerd met \textit{WebGL}. Deze technologie is gebaseerd op de OpenGL standaard. \textit{WebGL 2.0} laat toe om berekeningen uit te voeren en hierbij de parallelle rekenkracht van grafische processoren te gebruiken. Wanneer de grafische rekenkracht van een \textit{GPU} wordt ingezet om algemene calculaties uit te voeren wordt er gebruik gemaakt van een \textit{general purpose graphics processing unit} ook wel \textit{GPGPU} genoemd.

\begin{displayquote}[{\cite{Tavares2021}}]
    "The basic realization to understanding GPGPU in WebGL is that a texture is not an image, it's a 2D array of values."
\end{displayquote}

\textit{WebGL} gebruiken voor \textit{GPGPU} is echter een complexe implementatie die gebruik maakt van een \textit{global state} die volgens \textcite{Surma2022} al snel kan leiden tot complexe code, en hierdoor dus ook tot fouten. De implementatie van \textit{GPGPU} werd door de introductie van \textit{Transform Feedback} in WebGL 2.0 toegankelijker, maar deze nieuwere versie van \textit{WebGL} werd pas recent ondersteund door \textit{Apple} op \textit{Safari} in september 2021. \textit{WebGPU} vervangt dit \textit{global state} gedrag met \textit{pipelines} die niet aanpasbaar zijn eenmaal nadat ze zijn aangemaakt~\autocite{Beaufort2023}.

\begin{figure}
    \includegraphics[width=\linewidth]{WebGLAndGlobalState.jpeg}
    \caption[De \textit{Global State} in \textit{WebGL}~\autocite{GFXFundamentals2024}]{Gebruik van een globale variable binnen WebGL~\autocite{GFXFundamentals2024}.}
    \label{fig:WebGL Global State}
\end{figure}

\bigbreak{}

Afbeelding \ref{fig:WebGL Global State} toont de \textit{global state} die gebruikt wordt in WebGL.

\break{}

Het gebruiken van WebGL voor \textit{GPGPU} is niet enkel complex, het is ook inefficiënt. Data moet eerst als een \textit{texture} worden gecodeerd, daarna gedecodeerd in een \textit{shader}. Op dat moment moeten de eigenlijke berekeningen worden uitgevoerd. De resultaten van deze berekeningen moeten daarna opnieuw worden gecodeerd tot een \textit{texture}, alvorens er met de data kan worden verder gewerkt~\autocite{Surma2022}.

\bigbreak{}

Deze lange onnodige complexiteit komt verder uit het feit dat WebGL werd ontworpen voor het visualiseren van grafische elementen, en dus niet om algemene computationele taken uit te voeren zoals \textit{machine learning} of het mijnen van \textit{crypto currency}. Zoals eerder vermeld verbeterde de situatie wel met \textit{WebGL 2.0}, maar de ondersteuning hiervoor was beperkt en hierdoor kwam de proliferatie van lokale rekenkracht in de browser niet tot stand.

\break{}

\section{Introductie van WebGPU}

Omdat WebGPU wordt gestandaardiseerd door het \textit{World Wide Web Consortium}, krijgt het ook de nodige ondersteuning om een potentiële standaard te worden zoals \textit{WebGL}. Een globaal initiatief kan er dus wel toe leiden, dat deze technologie een revolutie betekent voor grafische weergave, en lokale rekenkracht op het Web. In tegenstelling tot de beperkte ondersteuning waar \textit{WebGL 2.0} op kon rekenen, zitten bij WebGPU wel alle browserfabrikanten mee in het ontwikkelingsproces~\autocite{Surma2022}.

\bigbreak{}

De werking van een GPU is heel complex. Hier wordt vaak te snel over gegaan. Er wordt door meerdere applicaties simultaan data naar het beeldscherm geprojecteerd waarbij de grafische kaart wordt opgedeeld. De veiligheidsimplicaties hiervan zijn niet te onderschatten, omdat deze applicaties elkaar niet mogen kunnen beïnvloeden of data van elkaar mogen uitlezen. Voor elke applicatie lijkt het dus dat deze over een monopolie beschikt van een grafische kaart. Uiteraard is dit niet het geval en wordt eigenlijk de rekenkracht verdeeld. Dit leidt ertoe dat de status van uitgevoerde taken moet worden bijgehouden omdat er altijd parallel wordt gewerkt. Programmeren voor \textit{General Purpose GPU} verloopt dus altijd op een multi threaded asynchrone manier, waar dus rekening mee moet gehouden worden~\autocite{Surma2022}.

\bigbreak{}

Uiteraard zijn er al meerdere implementaties van \textit{machine learning} op het web, maar deze worden beschikbaar gesteld door servers en er wordt dus nog geen gebruik gemaakt van \textit{client-sided WebGPU rendering}. \textcite{Fleetwood2023a} beweert dat het essentieel zal zijn dat modellen lokaal worden gedraaid om de echte \textit{real-time} te ondersteunen. Ook wanneer meerdere AI-modellen serieel worden gebruikt, om de functionaliteit van webapplicaties uit te breiden, verhoogt de vraag naar rekencapaciteit.

\bigbreak{}

Ook \textcite{Huyen2023} merkt in haar onderzoek op dat de kost van het draaien van AI-modellen in een productieomgeving enorm hoog kan oplopen. Hierdoor komt de rendabiliteit in gevaar. Dit is echter enkel het geval wanneer modellen suboptimaal worden ingezet zoals \textcite{Fleetwood2023a} opmerkt.

\begin{displayquote}[{\cite{Fleetwood2023a}}]
    "Offloading some parts of the call chain to finetuned local models could dramatically reduce costs while offering additional benefits such as privacy and personalization."
\end{displayquote}

\bigbreak{}

De \textit{WebGPU Shading Language} \(\textit{WGSL}\) \autocite{W3C2024}, is al opgemerkt als een moeilijke programmeer taal om mee te werken~\autocite{Madrigal2023, Ashton2020}.

Volgens \textcite{Fleetwood2023a} is dit echter niet het geval, en hij vindt dat de syntax toegankelijk is omdat het veel invloeden heeft van \textit{Rust}, een populaire opkomende taal.

\bigbreak{}

\textit{WebGPU} laat toe dat er rekenkracht beschikbaar wordt gesteld aan de browser maar dit wil niet zeggen dat hierdoor het probleem van de werking van complexe modellen lokaal in de browser is opgelost. Er is namelijk ook een geheugenlimiet omdat een model moet worden ingeladen. Hiervoor gaat de voorkeur naar het gebruik van het geheugen van de grafische kaart, indien deze te klein is geeft dit merkbare prestatie beperkingen. Er kan dus potentieel een \textit{bottleneck} ontstaan. Het efficiënt inladen en beschikbaar stellen van deze modellen is dus essentieel.

\break{}

\begin{figure}
    \includegraphics[width=\linewidth]{RadinMatrixMultiplicatie.png}
    \caption[Matrixvermenigvuldiging test~\autocite{Radin2021}]{Een test waarbij de prestaties van WebGPU, WebGL en JavaScript werden vergeleken~\autocite{Radin2021}.}
    \label{fig:Matrix Multiplication By Radin}
\end{figure}

\section{WebGPU in vergelijking met WebGL}

Uit de ondervindingen van \textcite{Radin2021} blijkt dat WebGPU tot 3,5 maal sneller kan zijn dan WebGL in simpele matrix multiplicatie. Dit komt enerzijds omdat het proces om de berekeningen uit te voeren met \textit{WebGPU} een stuk eenvoudiger is, maar ook omdat \textit{WebGPU} \textit{compute shaders} ondersteunt in tegenstelling tot \textit{WebGL}. Om berekeningen uit te voeren met \textit{WebGL} is het namelijk vereist dat de data eerst wordt omgezet naar pixels zodat deze met een \textit{pixel shader} kunnen worden berekend zoals eerder vermeld in \ref{sec:PowerOnWeb}. 

\bigbreak{}

Nog een nadeel van de afhankelijkheid op de \textit{pixel shader} van \textit{WebGL} is dat er gebruik moet gemaakt worden van het canvas object. \textcite{Radin2021} ondervond dat WebGL de matrix multiplicatie niet ondersteunt boven de 4096 x 4096, \textit{WebGPU} kon echter verder tot berekeningen uitvoeren tot bij matrices van 5000 x 5000. Het is ook belangrijk hierbij op te merken dat berekeningen uitgevoerd met \textit{WebGPU} asynchroon zijn, en omdat er geen conversie moet uitgevoerd worden van en naar de \textit{GPU buffer}, wordt ook deze vertraging uitgeschakeld. Ook moet de data die werd geproduceerd door de berekening niet met de synchrone functie \textit{getPixelsData} worden opgehaald. Deze zaken dragen toe aan het feit dat \textit{Javascript} implementaties die gebruik maakt van \textit{WebGPU} een lagere \textit{overhead} hebben en hierdoor minder moeten steunen op het hoofd proces.

\bigbreak{}

\begin{displayquote}[{\cite{Wallez2023}}]
    "As an example of the efficiency gains this can bring, an initial port of an image diffusion model in TensorFlow.js shows a 3x performance gain on a variety of hardware when moved from WebGL to WebGPU."
\end{displayquote}

\break{}

\section{Het nut van locale rekenkracht in de browser} 

\textcite{Fleetwood2022} merkt op dat er een paradigma verandering aankomt in hoe AI-modellen worden getraind. De huidige technologie werkt als volgt: informatie wordt door de gebruiker voorzien en opgestuurd naar een model dat beschikbaar is in de \textit{cloud} en dit model produceert een antwoord dat terug aan de gebruiker wordt voorgelegd.

\bigbreak{}

Dit paradigma is enigszins statisch, omdat het model dat draait in de cloud niet veranderlijk is. \textcite{Fleetwood2022} gelooft dat een standaard met modellen die dynamisch opgebouwd worden, de toekomst is. Dit wil zeggen dat gewichten die worden toegepast op een AI-model gepersonaliseerd zijn voor de gebruiker. Het is belangrijk om hierbij de privacy aspecten te erkennen. Ook valt op te merken dat locale beschikbaarheid van rekenkracht op het web, en dus WebGPU, een katalysator zou kunnen zijn voor zo een revolutionaire verandering.

\begin{displayquote}[{\cite{Fleetwood2022}}]
    "It would be optimal if the subset of weights that get updated to learn about the user remained on their device."
\end{displayquote}

Wat \textcite{Fleetwood2022} ook opmerkt is dat er bij het draaien van  AI-technologieën vaak meerdere processen serieel werken. Juist omdat er verder wordt gewerkt op informatie die reeds werd gegenereerd, leent deze technologie zich voor een tussenoplossing. Deze zou toestaan een hybride cloud te maken waarbij een deel van de computationele taken worden overgedragen aan de eindgebruiker.

\bigbreak{}

Er moet nog wel worden benadrukt dat het downloaden van modellen een groot struikelblok voor de technologie kan vormen. Veel modellen worden niet publiek gemaakt, dus die kunnen van deze implementatie geen gebruik maken. AI-modellen die te groot zijn zorgen ervoor dat de eind-gebruiker initieel moet wachten tot deze gedownload zijn alvorens de webapplicatie volledig beschikbaar is. Deze leiden tot een verminderde bruikbaarheid. Maar volgens \textcite{Fleetwood2022} zijn dit problemen die door middel van compressie en cashing grotendeels verholpen kunnen worden.

\break{}

\begin{figure}
    \includegraphics[width=\linewidth]{browsersupport.png}
    \caption[Ondersteuning voor \textit{WebGPU}~\autocite{Deveria2024}]{
        De \textit{Browser} ondersteuning voor \textit{WebGPU} te vinden op \href{https://caniuse.com/webgpu}{caniuse.com/webgpu}~\autocite{Deveria2024}.
    }
    \label{fig:Browser Support}
\end{figure}

\begin{figure}
    \includegraphics[width=\linewidth]{browsersupportuserrelative.png}
    \caption[\textit{Browser} gebruiker toegang tot \textit{WebGPU}~\autocite{Deveria2024}]{
        Ondersteuning voor \textit{WebGPU} te vinden op \href{https://caniuse.com/webgpu}{caniuse.com/webgpu} relatief tot gebruikers~\autocite{Deveria2024}.
    }
    \label{fig:Relative Browser Support}
\end{figure}

\section{WebGPU browser ondersteuning}

WebGPU wordt nog niet door alle browsers ondersteund. Het is dus belangrijk dat de \textit{early-adopter} gebruikers verifiëren dat hun browser compatibel is. Dit kan makkelijk worden uitgezocht door gebruik te maken van \href{https://caniuse.com/webgpu}{caniuse.com}.

\bigbreak{}

Merkwaardig is ook dat Chrome, als grootste speler binnen de markt, reeds volledige ondersteuning biedt vanaf in versie 113~\autocite{Deveria2024}.

\bigbreak{}

Afbeelding \ref{fig:Browser Support} toont de ondersteuning voor \textit{WebGPU} binnen verschillende \textit{browsers}. Hieruit zo kunnen worden afgeleid dat \textit{WebGPU} nog niet is doorgebroken, dit is echter niet het geval.

\bigbreak{}
\newdate{date}{06}{05}{2024}
\date{\displaydate{date}}

Afbeelding \ref{fig:Relative Browser Support} toont een correcter beeld. Hierbij is de grafiek omgevormd relatief tot de verdeling van het aantal gebruikers per browser en versie. Op  \displaydate{date} heeft 70,51\% van de totale browser gebruikers toegang tot \textit{WebGPU}, volgens statistische informatie beschikbaar gesteld door \textcite{Deveria2024}.