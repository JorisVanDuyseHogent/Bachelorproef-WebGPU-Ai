\chapter{Meetresultaten}%
\label{ch:benchmarks}

De performantie van WebGPU in vergelijking met andere technologieën kan sterk verschillen. 

Een traditionele aanpak van \textit{GPU} acceleratie is door het gebruik van GPU APIs. Zo bestaan er onderliggend in besturingssystemen APIs zoals Direct3D 12, Vulcan en Metal. Deze grafische APIs zorgen telkens voor de communicatie tussen applicaties en de onderliggende grafische computeronderdelen. En laten dus voor computationeel complexe programma's toe om parallelle berekeningen uit te voeren op krachtige grafische kaarten.

\bigbreak{}

Het is echter duidelijk dat het onderhouden van software voor verschillende besturingssystemen complex is en veel energie vergt. Dit is een probleem dat WebGPU verhelpt door een abstractie laag te vormen boven deze APIs. \autocite{Wallez2023} 

\break{}

\section{WebGPU versus WASM}

Een andere opkomende technologie is  \textit{web asambly} (WASM). WASM is een zeer compact \textit{assembly-like binary} die performantie toelaat vergelijkbaar met \textit{native} talen zoals C/C++ en Rust. \autocite{Steiner2023} Deze \textit{low-level} programmeer talen laten net zoals \textit{WGSL} voor WebGPU toe dat rekenkundige taken op een optimale manier worden uitgevoerd.

\bigbreak{}

\input{graphs/HuggingFaceTransformerBenchmark.tex}

Door de \textit{webgpu-embedding-benchmark} van \textcite{Lochner2024} uit te voeren met verschillende test-opstellingen blijkt WebGPU consistent sneller dan WASM. In deze test werd de uitvoeringstijd gemeten van \textit{BERT-based embedding models} met zowel WebGPU als WASM, en dit telkens voor een toenemende \textit{batch size}.

\bigbreak{}

Voor een \textit{batch-size} van 64 doet de \textit{Xeon E5-2680 V2} gemiddeld 60s over de transformer test. Wanneer deze tijd als basis wordt genomen is de Intel Core i9-9980HK 10 seconden sneller.

\bigbreak{}

Om deze test uit te voeren werd de \textit{Sequence length} ingesteld op 512 en alle testen werden uitgevoerd op Chrome 124.0.6367.93.

\break{}

\begin{tabular}{ |p{5cm}|p{3cm}|p{3cm}|p{3cm}|  }
    \hline
    \multicolumn{4}{|c|}{Vergelijken van theoretische \textit{Floating Point} performantie} \\
    \hline
    Component& Theoretisch GFLOPS & Theoretisch baseline & Meetresultaten WASM WebGPU\\
    \hline
        Xeon E5-2680 V2             & 224,0     & 100\%  & 100\%       \\
        Intel Core i9-9980HK        & 307,2     & 137\%  & 129\%    \\
        Intel UHD Graphics 630      & 403,2     & 180\%  & 560\%    \\
        Nvidia Geforce GTX 1080 Ti  & 11.340,0  & 5063\% & 7170\%   \\
    \hline
\end{tabular}

\bigbreak{}

De Xeon E5-2680 V2 werd als basis gebruikt om de andere componenten te vergelijken. Omdat de \textit{Intel Core i9-9980HK} een nieuwere processor is, is deze c.a. 30\% sneller. Voor beide deze processoren werd de Intel specificatie gebruikt om de theoretische GFLOPS te bepalen. \autocite{Intel2024, Intel2024a}

\bigbreak{}

De GFLOPS voor de grafische kaarten werd gebaseerd op informatie die beschikbaar werd gesteld door \textcite{TechPowerUp2017, TechPowerUp2017a}.

\bigbreak{}

Uit de grafiek en de tabel valt af te leiden dat voor deze test WebGPU beter presteert dan WASM. Deze test toont enkel resultaten die vergelijkbaar zijn wanneer kunstmatige intelligentie modellen getraind worden vanuit de browser. Deze test is niet representatief voor alle scenario's, zoals bijvoorbeeld het operationeel draaien van een model.

\bigbreak{}

Ook valt af te leiden uit de resultaten van de \textit{webgpu-embedding-benchmark} van \textcite{Lochner2024} dat WebGPU beter presteert dan verwacht uit de theoretische snelheden. Dit ligt aan de implementatie van de test. Net zoals \textit{WebGPU} is \textit{WebAssembly} een nieuwe technologie. Beide technologieën zijn nog in ontwikkeling en kunnen nog verder verbeterd worden om de prestaties te verhogen.

\section{WebGL versus WebGL 2.0 en WebGPU}

Grafische rendering op het web werd sinds 2011 afgehandeld door \textit{WebGL}. Deze technologie is echter verouderd en werd vervangen met \textit{WebGL 2.0} in 2017. Sinds \textit{WebGL 2.0} zijn er nieuwe grafische technologieën op de markt zoals \textit{ray tracing}, waarbij individuele fotonen worden gesimuleerd om extreem realistische belichting te simuleren. Deze nieuwe technologieën werden niet verwerkt in WebGL maar worden wel verwacht in WebGPU.

\break{}

\section{Whisper Cuda versus WebGPU}

Omdat de ai-modellen van Whisper online werden gepubliceerd door OpenAI; laat dit toe de vergelijking te maken van Whisper op Cuda en Whisper ondersteund door WebGPU. Fleetwood heeft namelijk een implementatie van WhisperAI met WebGPU beschikbaar op \href{https://github.com/openai/whisper}{GitHub.com/OpenAI/Whisper}.

\bigbreak{}
\begin{table}
    \begin{tabular}{ |p{1.5cm}|p{2.5cm}|p{3cm}|p{3cm}|p{2cm}|p{2cm}|  }
        \hline
        \multicolumn{6}{|c|}{Beschikbare modellen en talen Whisper} \\
        \hline
            Size& Parameters & English-only model & Multilingual model & Required VRAM & Relative speed\\
        \hline
            tiny&       39 M    &tiny.en    & tiny& ~1 GB& ~32x     \\
            base &      74 M	&base.en    & base & ~1 GB & ~16x   \\
            small &     244 M	&small.en   & small & ~2 GB & ~6x   \\
            medium &    769 M	&medium.en  & medium & ~5 GB & ~2x  \\
            large &     1550 M	&N/A        & large & ~10 GB& 	1x  \\
        \hline
    \end{tabular}
    \caption{Whisper modellen beschikbaar gesteld door \textcite{OpenAI2023}.}
    \label{tab:OpenAIWhisperModels}
\end{table}

\bigbreak{}

\subsection*{Installatie afhankelijkheden}

Om Whisper werkende te krijgen op een \textit{Windows 10} installatie zijn er verschillende afhankelijkheden die moeten worden geinstalleerd.

\bigbreak{}

\begin{enumerate}
    \item Python 3.9.9 of later 
    \item PyTorch 1.10.1 of later
    \item CUDA Toolkit
    \item 
\end{enumerate}

\bigbreak{}

Bij de installatie van deze afhanklijkheden werd echter ondervonden dat de Torch installatie CUDA enabled moet zijn, 

% PS > pip3 uninstall torch torchvision==0.15.0 torchaudio==2.0.0
% PS > pip3 cache purge
% Files removed: 610
% PS > pip3 install torch torchvision==0.15.0 torchaudio==2.0.0 --index-url https://download.pytorch.org/whl/cu117

% \begin{tcolorbox}[
%     boxrule=0pt,
%     sharp corners
% ]
\begin{lstlisting}[language=python]
import torch
torch.cuda.is_available()
# returns False
torch.zeros(1).cuda()
# throws AssertionError: Torch not compiled with CUDA enabled
\end{lstlisting}
% \end{tcolorbox}


\begin{lstlisting}[language=python]
import torch
torch.cuda.is_available()
# returns True
torch.zeros(1).cuda()
# returns tensor([0.], device='cuda:0')
\end{lstlisting}

% >>> import torch
% >>> torch.cuda.is_available()
% False
% >>> torch.zeros(1).cuda()
% Traceback (most recent call last):
%   File "<stdin>", line 1, in <module>
%   File "PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\torch\cuda\__init__.py", line 239, in _lazy_init
% AssertionError: Torch not compiled with CUDA enabled

% >>> import torch
% >>>
% >>> torch.cuda.is_available()
% True
% >>> torch.zeros(1).cuda()
% tensor([0.], device='cuda:0')

\input{graphs/WhisperBenchmark.tex}

\section{wgpu-bench}

Om de performantie te testen van WebGPU werd wgpu-bench uitgevoerd.

Hiervoor werd rust geïnstalleerd, en gebruik gemaakt van Visual Studio Community 2022 in combinatie met Visual Studio Build-Tools 2022, waarbij de \textit{Desktop development with C++} module werd meegeïnstalleerd.

De broncode moest hierna gebouwd worden.

% rustup default nightly-x86_64-pc-windows-msvc